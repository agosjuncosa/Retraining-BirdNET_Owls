{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69972163-6523-4c3b-a45d-a93d2498c627",
   "metadata": {},
   "source": [
    "### Evaluation Histogram Plot \n",
    "\n",
    "To visualize the performance we will plot histograms of classifier logit scores for positive and negative samples. We need to transform the scores back into the logit scale because now they are contained from 0,1 and we need them to be -inf +inf with the 0 in the middle. We will use the one-hot-labeled evaluation set and the continues scores. In the one hot eval set we will use 0 as negative and 1 as positive. Then we will plot the frequency of predictions accoridng to each score and paint the predictions according to the true label. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9413fab1-d6e2-4ada-a269-103d0c2d4fbc",
   "metadata": {},
   "source": [
    "The center (logit = 0) corresponds to 50% probability\n",
    "\n",
    "Higher logits = more confident predictions for positives\n",
    "\n",
    "Lower logits = more confident for negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeff582-82d9-45cd-a264-67dc4f01855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import logit\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "#set up plotting\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize']=[15,5] #for large visuals\n",
    "%config InlineBackend.figure_format = 'retina'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e14651-3f74-43fd-9eb4-ee2bb8faabb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the CSV files\n",
    "true_labels_path = ('/mnt/d/retraining_BirdNET_2025/model_test/input_ready/one-hot-encoded_validation1.csv')\n",
    "predictions_path = ('/mnt/d/retraining_BirdNET_2025/model_test/results/model_4_04282025/m4_predicted_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d8cb6d-b033-43cb-9ea1-a2db78cad40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrames\n",
    "true_df = pd.read_csv(true_labels_path)\n",
    "pred_df = pd.read_csv(predictions_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246b9559-6f22-4b72-99d9-d8df5cc28ae9",
   "metadata": {},
   "source": [
    "#### If want to perform class specific histogram **run 1** for overall performance historgram **run 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5ddcd1-c7a4-4c36-b35e-c6b9f2b9794c",
   "metadata": {},
   "source": [
    "### 1. To plot class specific histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9eec1c-f7de-4520-81eb-38c260d453f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract class columns (skip first 3 columns: file, start_time, end_time)\n",
    "class_columns = true_df.columns[3:]\n",
    "\n",
    "# Choose class to plot\n",
    "class_name = \"Black-capped Screech-Owl\"  # Change this to any class name\n",
    "if class_name not in class_columns:\n",
    "    raise ValueError(f\"Class '{class_name}' not found in the data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a8b882-184c-4963-9c88-ccfb3d2571b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract true labels and prediction scores\n",
    "true_labels = true_df[class_name].values\n",
    "pred_probs = pred_df[class_name].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc114806-15d5-49a3-baa0-1c2374d69d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to logits\n",
    "eps = 1e-6  # avoid logit(0) or logit(1)\n",
    "pred_probs = np.clip(pred_probs, eps, 1 - eps)\n",
    "logits = logit(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c9b4fb-ec87-4868-a326-95080217338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by true/false labels\n",
    "logits_pos = logits[true_labels == 1]\n",
    "logits_neg = logits[true_labels == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c407e143-2b6d-4631-8988-8603580d9c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "# Set up bins\n",
    "bins = np.linspace(-10, 10, 20)  # Adjust range & bin width as needed\n",
    "\n",
    "\n",
    "plt.hist(logits_neg, bins=bins, alpha=0.5, label=\"Negatives\", color='sandybrown')\n",
    "#plt.hist(logits_pos, bins=bins, alpha=0.5, label=\"Positives\", color='skyblue')\n",
    "\n",
    "# Get current axis object\n",
    "ax = plt.gca()\n",
    "\n",
    "# Set title and axis labels with font size\n",
    "ax.set_title(f\"M3-strong-neg {class_name} Logit Score Distribution\", fontsize=18)\n",
    "ax.set_xlabel(\"Logit Score\", fontsize=20)\n",
    "ax.set_ylabel(\"Count\", fontsize=20)\n",
    "# Set tick font sizes\n",
    "ax.tick_params(axis='both', labelsize=16)  # for both x and y ticks\n",
    "\n",
    "# Customize legend font size\n",
    "plt.legend(loc='upper right', fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save BEFORE showing\n",
    "output_dir = os.path.dirname(predictions_path)\n",
    "plot_path = os.path.join(output_dir, \"M4_Black-capped Screech-Owl_logit_histogram_neg.png\")\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "print(f\"Plot saved to: {plot_path}\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a592153-87d6-4aa2-a19a-2c5e582ba8c9",
   "metadata": {},
   "source": [
    "### 2. To plot overal performance histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648a7932-558f-463f-870e-b0c84dfc8d5b",
   "metadata": {},
   "source": [
    "### a. To compute only for owl species or classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d361171-b3e6-4600-b080-b760c82fe505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If want to compute histogram exclusively for owls\n",
    "# Find columns that contain the word \"Owl\" (case-insensitive)\n",
    "owl_columns = [col for col in true_df.columns[3:] if \"owl\" in col.lower()]\n",
    "\n",
    "if not owl_columns:\n",
    "    raise ValueError(\"No columns found containing 'owl' in their name.\")\n",
    "\n",
    "print(f\"Using these columns for 'owl':\\n{owl_columns}\")\n",
    "\n",
    "# Get values for only those owl-related classes\n",
    "true_values = true_df[owl_columns].values.flatten()\n",
    "pred_probs = pred_df[owl_columns].values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bae4521-a36b-40fc-8c99-ea6401912ec2",
   "metadata": {},
   "source": [
    "### b. To compute for all classes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a3ae8a9-de7a-423f-a27e-f5923f5b82bb",
   "metadata": {},
   "source": [
    "# Extract class label columns (skip metadata)\n",
    "true_values = true_df.iloc[:, 3:].values.flatten()\n",
    "pred_probs = pred_df.iloc[:, 3:].values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7453ce01-ccec-41d4-b80e-a5547fd4ac2c",
   "metadata": {},
   "source": [
    "### From here on there is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164fa811-9406-4e75-8729-53ce5061c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip predicted probabilities to avoid 0 and 1\n",
    "eps = 1e-6\n",
    "pred_probs = np.clip(pred_probs, eps, 1 - eps)\n",
    "\n",
    "# Convert to logit scale\n",
    "logits = logit(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed374c-82bc-4cce-90f8-6e9e263e2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split logits by true vs false\n",
    "logits_pos = logits[true_values == 1]\n",
    "logits_neg = logits[true_values == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91550307-b43d-469d-95ed-0842f339361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "# Set up bins\n",
    "bins = np.linspace(-10, 15, 20)  # Adjust range & bin width as needed\n",
    "\n",
    "\n",
    "#plt.hist(logits_neg, bins=bins, alpha=0.5, label=\"Negatives\", color='mediumaquamarine')\n",
    "plt.hist(logits_pos, bins=bins, alpha=0.7, label=\"Positives\", color='salmon')\n",
    "\n",
    "# Get current axis object\n",
    "ax = plt.gca()\n",
    "\n",
    "# Set title and axis labels with font size\n",
    "ax.set_title(\"BN Model Overall Logit Score (Owl Species)\", fontsize=18)\n",
    "ax.set_xlabel(\"Logit Score\", fontsize=20)\n",
    "ax.set_ylabel(\"Count\", fontsize=20)\n",
    "# Set tick font sizes\n",
    "ax.tick_params(axis='both', labelsize=16)  # for both x and y ticks\n",
    "\n",
    "# Customize legend font size\n",
    "plt.legend(loc='upper left', fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save BEFORE showing\n",
    "output_dir = os.path.dirname(predictions_path)\n",
    "plot_path = os.path.join(output_dir, \"bn_logit_histogram_owl_sp_pos.png\")\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "print(f\"Plot saved to: {plot_path}\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
