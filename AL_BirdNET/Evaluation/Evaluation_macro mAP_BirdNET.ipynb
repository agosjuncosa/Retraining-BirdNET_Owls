{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "006f4618-7261-474b-83cf-26a9d669d95e",
   "metadata": {},
   "source": [
    "### macro mAP retrain vs BirdNET for different dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79c55e8d-6fc5-409c-be9d-a34c3602416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67ba1f6e-b978-452e-94f2-cad0e8f9751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the CSV files\n",
    "true_labels_path = ('/mnt/d/retraining_BirdNET_2025/model_test/input_ready/one-hot-encoded_validation1_ARU.csv')\n",
    "predictions_path = ('/mnt/d/retraining_BirdNET_2025/model_test/results//model_5_05232025/m5_predicted_labels_ARU.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fde78700-ad9e-4642-816f-76edaae2037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrames\n",
    "true_labels_df = pd.read_csv(true_labels_path)\n",
    "predictions_df = pd.read_csv(predictions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29b9ca73-e675-45dc-a324-07507c5d0bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract label data, assuming columns are ordered and named the same beyond the first three columns\n",
    "# The first three columns are assumed to be 'file', 'start_time', 'end_time' which are not part of the labels\n",
    "true_labels = true_labels_df.iloc[:, 3:].values\n",
    "predictions = predictions_df.iloc[:, 3:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "585ba322-f4c7-4aea-b464-f4068d52dccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Mean Average Precision: 0.3056276653364683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agosjuncosa/anaconda3/envs/opensoundscape/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/agosjuncosa/anaconda3/envs/opensoundscape/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/agosjuncosa/anaconda3/envs/opensoundscape/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/agosjuncosa/anaconda3/envs/opensoundscape/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/agosjuncosa/anaconda3/envs/opensoundscape/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/agosjuncosa/anaconda3/envs/opensoundscape/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/agosjuncosa/anaconda3/envs/opensoundscape/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/agosjuncosa/anaconda3/envs/opensoundscape/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Calculate the macro mean average precision\n",
    "macro_mAP = average_precision_score(true_labels, predictions, average='macro')\n",
    "\n",
    "print(f'Macro Mean Average Precision: {macro_mAP}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c2f8e1-89d7-4972-b7c7-3e04b09cfa85",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Calculate precision-recall for each class and average precision over all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2090555-4a00-4439-829b-25089dafd50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
    "# Assuming you already have `true_labels` and `predictions` (e.g., probabilities or decision function output)\n",
    "n_classes = true_labels.shape[1]  # This should match the number of classes\n",
    "\n",
    "\n",
    "# For each class, calculate precision, recall, and average precision\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "\n",
    "# Loop through each class\n",
    "for i in range(n_classes):\n",
    "    # Check if there are any positive samples for the current class\n",
    "    precision[i], recall[i], _ = precision_recall_curve(true_labels[:, i], predictions[:, i])\n",
    "    average_precision[i] = average_precision_score(true_labels[:, i], predictions[:, i])\n",
    "\n",
    "# Calculate macro-average precision-recall\n",
    "precision[\"macro\"], recall[\"macro\"], _ = precision_recall_curve(true_labels.ravel(), predictions.ravel())\n",
    "average_precision[\"macro\"] = average_precision_score(true_labels, predictions, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70d80bb-5791-432a-b66c-3cd4b9cc391e",
   "metadata": {},
   "source": [
    "### Plot macro mean average precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6596c997-5e08-471d-acc5-a81daa8738bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the precision-recall curve using the macro-average\n",
    "display = PrecisionRecallDisplay(\n",
    "    recall=recall[\"macro\"],\n",
    "    precision=precision[\"macro\"],\n",
    "    average_precision=average_precision[\"macro\"],\n",
    "    prevalence_pos_label=Counter(true_labels.ravel())[1] / true_labels.size,\n",
    ")\n",
    "\n",
    "# Customize line color (e.g., set to red)\n",
    "display.plot(plot_chance_level=False, color='palevioletred')\n",
    "\n",
    "# Move the legend inside the plot\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.title(\"Model-4 Macro-averaged over all classes\")\n",
    "\n",
    "# Save the plot as PNG or JPG\n",
    "plt.savefig('/mnt/d/retraining_BirdNET_2025/model_test/results/model_4_04282025/m4_AP_curve.png', format='png', dpi=300)  # PNG format\n",
    "# plt.savefig('precision_recall_curve.jpg', format='jpg', dpi=300)  # JPG format\n",
    "\n",
    "# Show the plot\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1389429-9cfa-4fbf-9176-4e9831c975b3",
   "metadata": {},
   "source": [
    "### Plot average precision for specific classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3ea014-ad50-43d1-a452-cf1b5ac70103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "\n",
    "# Get the class names starting from column 4\n",
    "class_names = true_labels_df.iloc[:, 3:].columns\n",
    "\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5c9dd2-0a34-488e-947f-550854922fb5",
   "metadata": {},
   "source": [
    "### Frog type Owls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd3ae61-6ed7-44de-9b05-b73f7a0ab443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the class indices you want to plot\n",
    "selected_class_names = ['Long-tufted Screech-Owl','Buff-fronted Owl','Black-capped Screech-Owl']\n",
    "\n",
    "# Get the corresponding indices for the selected class names\n",
    "selected_classes = [list(class_names).index(class_name) for class_name in selected_class_names]\n",
    "\n",
    "# Setup plot details\n",
    "colors = cycle([\"turquoise\", \"darkorange\",\"palevioletred\"])\n",
    "\n",
    "# Create the plot\n",
    "_, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot precision-recall curve for each selected class\n",
    "for class_name, class_idx, color in zip(selected_class_names, selected_classes, colors):\n",
    "    display = PrecisionRecallDisplay(\n",
    "        recall=recall[class_idx],\n",
    "        precision=precision[class_idx],\n",
    "        average_precision=average_precision[class_idx],\n",
    "    )\n",
    "    display.plot(ax=ax, name=f\"Precision-recall for {class_name}\", color=color)\n",
    "\n",
    "# Add title and legend\n",
    "\n",
    "\n",
    "ax.set_title(\"Precision-Recall Frog-type Owls Model-4\")\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))  # Adjust location to the right of the plot\n",
    "\n",
    "# Adjust layout to make room for the legend\n",
    "plt.tight_layout(rect=[1, 1, 0.75, 2]) \n",
    "# Save the plot as PNG or JPG\n",
    "plt.savefig('/mnt/d/retraining_BirdNET_2025/model_test/results/model_4_04282025/m4_frog-type-owls_pr_curve.png', format='png', dpi=300, bbox_inches='tight')  # PNG format\n",
    "# plt.savefig('precision_recall_curve.jpg', format='jpg', dpi=300)  # JPG format\n",
    "\n",
    "# Show the plot\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019080a8-1dc1-4f33-be47-fb4e124f55c0",
   "metadata": {},
   "source": [
    "### Low pitched Owls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3961699-d5a8-45fc-ab4a-120679ace861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the class indices you want to plot\n",
    "selected_class_names = ['Burrowing Owl_call','Mottled Owl_song', 'Rusty-barred Owl_call', 'Black-banded Owl',\n",
    "                        'Rusty-barred Owl_song', 'Tawny-browed Owl','Striped Owl_song', 'Stygian Owl_song']\n",
    "\n",
    "# Get the corresponding indices for the selected class names\n",
    "selected_classes = [list(class_names).index(class_name) for class_name in selected_class_names]\n",
    "\n",
    "# Setup plot details\n",
    "colors = cycle([\"orchid\", \"olivedrab\", \"turquoise\", \"orange\", \"slateblue\", \"navy\",  \"tan\",\"lightsalmon\"])\n",
    "\n",
    "# Create the plot\n",
    "_, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot precision-recall curve for each selected class\n",
    "for class_name, class_idx, color in zip(selected_class_names, selected_classes, colors):\n",
    "    display = PrecisionRecallDisplay(\n",
    "        recall=recall[class_idx],\n",
    "        precision=precision[class_idx],\n",
    "        average_precision=average_precision[class_idx],\n",
    "    )\n",
    "    display.plot(ax=ax, name=f\"Precision-recall for {class_name}\", color=color)\n",
    "\n",
    "# Add title and legend\n",
    "\n",
    "\n",
    "ax.set_title(\"Precision-Recall curve low-pitched Owls Model-4\")\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))  # Adjust location to the right of the plot\n",
    "\n",
    "# Adjust layout to make room for the legend\n",
    "plt.tight_layout(rect=[1, 1, 0.75, 2]) \n",
    "# Save the plot as PNG or JPG\n",
    "plt.savefig('/mnt/d/retraining_BirdNET_2025/model_test/results/model_4_04282025/m4_low-pitched-owls_pr_curve.png', format='png', dpi=300, bbox_inches='tight')  # PNG format\n",
    "# plt.savefig('precision_recall_curve.jpg', format='jpg', dpi=300)  # JPG format\n",
    "\n",
    "# Show the plot\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033644de-a91a-47de-a09a-45b2680f400a",
   "metadata": {},
   "source": [
    "### High pitched owls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742885ac-2144-4164-aab2-e52c94d206cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the class indices you want to plot\n",
    "selected_class_names = ['Burrowing Owl_song', 'Striped Owl_call','Barn Owl', 'Mottled Owl_call',\n",
    "                        'Stygian Owl_call','Rusty-barred Owl_call1']\n",
    "\n",
    "# Get the corresponding indices for the selected class names\n",
    "selected_classes = [list(class_names).index(class_name) for class_name in selected_class_names]\n",
    "\n",
    "# Setup plot details\n",
    "colors = cycle([\"darkseagreen\", \"lightsalmon\", \"lightseagreen\", \"plum\", \"gold\", \"lightsteelblue\"])\n",
    "\n",
    "# Create the plot\n",
    "_, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot precision-recall curve for each selected class\n",
    "for class_name, class_idx, color in zip(selected_class_names, selected_classes, colors):\n",
    "    display = PrecisionRecallDisplay(\n",
    "        recall=recall[class_idx],\n",
    "        precision=precision[class_idx],\n",
    "        average_precision=average_precision[class_idx],\n",
    "    )\n",
    "    display.plot(ax=ax, name=f\"Precision-recall for {class_name}\", color=color)\n",
    "\n",
    "# Add title and legend\n",
    "\n",
    "\n",
    "ax.set_title(\"Precision-Recall curve high-pitched Owls Model-4\")\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))  # Adjust location to the right of the plot\n",
    "\n",
    "# Adjust layout to make room for the legend\n",
    "plt.tight_layout(rect=[1, 1, 0.75, 2]) \n",
    "# Save the plot as PNG or JPG\n",
    "plt.savefig('/mnt/d/retraining_BirdNET_2025/model_test/results/model_4_04282025/m4_high-pitch-owls_pr_curve.png', format='png', dpi=300, bbox_inches='tight')  # PNG format\n",
    "# plt.savefig('precision_recall_curve.jpg', format='jpg', dpi=300)  # JPG format\n",
    "\n",
    "# Show the plot\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d51fd19-4307-4260-a408-f354938548b7",
   "metadata": {},
   "source": [
    "#### Common Owls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94ebc8e-be40-4c45-aee2-247e289e9b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the class indices you want to plot\n",
    "selected_class_names = ['Tropical Screech-Owl','Ferruginous Pygmy-Owl']\n",
    "\n",
    "# Get the corresponding indices for the selected class names\n",
    "selected_classes = [list(class_names).index(class_name) for class_name in selected_class_names]\n",
    "\n",
    "# Setup plot details\n",
    "colors = cycle([\"darkseagreen\", \"lightsalmon\"])\n",
    "\n",
    "# Create the plot\n",
    "_, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot precision-recall curve for each selected class\n",
    "for class_name, class_idx, color in zip(selected_class_names, selected_classes, colors):\n",
    "    display = PrecisionRecallDisplay(\n",
    "        recall=recall[class_idx],\n",
    "        precision=precision[class_idx],\n",
    "        average_precision=average_precision[class_idx],\n",
    "    )\n",
    "    display.plot(ax=ax, name=f\"Precision-recall for {class_name}\", color=color)\n",
    "\n",
    "# Add title and legend\n",
    "\n",
    "\n",
    "ax.set_title(\"Precision-Recall curve Common Owls Model-4\")\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))  # Adjust location to the right of the plot\n",
    "\n",
    "# Adjust layout to make room for the legend\n",
    "plt.tight_layout(rect=[1, 1, 0.75, 2]) \n",
    "# Save the plot as PNG or JPG\n",
    "plt.savefig('/mnt/d/retraining_BirdNET_2025/model_test/results/model_4_04282025/m4_common-owls_pr_curve.png', format='png', dpi=300, bbox_inches='tight')  # PNG format\n",
    "# plt.savefig('precision_recall_curve.jpg', format='jpg', dpi=300)  # JPG format\n",
    "\n",
    "# Show the plot\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e392acf5-2242-4708-b73d-2cb74c617cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the class indices you want to plot\n",
    "selected_class_names = ['Little Nightjar','Rufous Nightjar','Long-tailed Potoo',\n",
    "                        'Ocellated Poorwill','Short-tailed Nighthawk', 'Common Potoo',\n",
    "                         'Common Pauraque','Silky-tailed Nightjar']\n",
    "\n",
    "# Get the corresponding indices for the selected class names\n",
    "selected_classes = [list(class_names).index(class_name) for class_name in selected_class_names]\n",
    "\n",
    "# Setup plot details\n",
    "colors = cycle([\"darkseagreen\", \"lightsalmon\", \"lightseagreen\", \"orchid\", \"gold\", \"lightsteelblue\", \"olive\", \"yellowgreen\",\"paleturquoise\"])\n",
    "\n",
    "# Create the plot\n",
    "_, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot precision-recall curve for each selected class\n",
    "for class_name, class_idx, color in zip(selected_class_names, selected_classes, colors):\n",
    "    display = PrecisionRecallDisplay(\n",
    "        recall=recall[class_idx],\n",
    "        precision=precision[class_idx],\n",
    "        average_precision=average_precision[class_idx],\n",
    "    )\n",
    "    display.plot(ax=ax, name=f\"Precision-recall for {class_name}\", color=color)\n",
    "\n",
    "# Add title and legend\n",
    "\n",
    "\n",
    "ax.set_title(\"Precision-Recall curve Caprimulgids Model-4\")\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))  # Adjust location to the right of the plot\n",
    "\n",
    "# Adjust layout to make room for the legend\n",
    "plt.tight_layout(rect=[1, 1, 0.75, 2]) \n",
    "# Save the plot as PNG or JPG\n",
    "plt.savefig('/mnt/d/retraining_BirdNET_2025/model_test/results/model_4_04282025/m4_caprimulgids_pr_curve.png', format='png', dpi=300, bbox_inches='tight')  # PNG format\n",
    "# plt.savefig('precision_recall_curve.jpg', format='jpg', dpi=300)  # JPG format\n",
    "\n",
    "# Show the plot\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
