{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09a9430e-e63d-448b-b57e-192e9762a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from opensoundscape import Audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7599da0-b30f-429e-96e0-1c0ea698bf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "annotations_file = '/mnt/d/retraining_BirdNET_2025/iterative_training/results/model_10_M12/BirdNET_SelectionTable.txt'\n",
    "output_dir = '/mnt/d/retraining_BirdNET_2025/iterative_training/segments_validation/it_M10/'\n",
    "# Parameters\n",
    "num_clips_default = 80  # Default number of clips to select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "880c8ee6-577e-4232-aa86-9cad9435618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BirdNET predictions\n",
    "predictions = pd.read_csv(annotations_file, sep='\\t', usecols=['Begin Path', 'File Offset (s)', 'Common Name', 'Confidence'])\n",
    "predictions.rename(columns={\n",
    "    'Begin Path': 'file_path',\n",
    "    'File Offset (s)': 'offset',\n",
    "    'Common Name': 'class',\n",
    "    'Confidence': 'score'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b14dff2a-c52b-4ccc-91c1-0f5aacd98757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct `offset_filename` using ONLY offset and filename with extension\n",
    "predictions['offset_filename'] = predictions.apply(\n",
    "    lambda row: f\"{int(row['offset'])}_{Path(row['file_path']).name}\", axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "861640cc-ccab-4a78-b665-fa938c6ef8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract elements 1 to 5 of the filename for comparison\n",
    "def extract_core_filename(filename):\n",
    "    parts = Path(filename).stem.split('_')\n",
    "    return '_'.join(parts[1:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a59825de-6953-4c28-a22a-f91a348ada6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predictions: 48616 clips\n"
     ]
    }
   ],
   "source": [
    "# Apply extraction to predictions\n",
    "predictions['core_filename'] = predictions['offset_filename'].apply(extract_core_filename)\n",
    "\n",
    "# Display result for verification\n",
    "print(f\"Total predictions: {len(predictions)} clips\")\n",
    "\n",
    "# Group by class and select top-scoring clips\n",
    "selected_clips = []\n",
    "for class_name, group in predictions.groupby('class'):\n",
    "    if class_name.lower() == 'nocall':\n",
    "        continue  # Skip 'nocall' predictions\n",
    "\n",
    "    # Sort by score in descending order\n",
    "    group = group.sort_values(by='score', ascending=False)\n",
    "\n",
    "    # Select top N clips (you can customize this per class if needed)\n",
    "    selected_clips.append(group.head(num_clips_default))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b3d6911-2c75-4ad3-805d-2e2c3f0bbd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all selected clips into a single DataFrame\n",
    "if selected_clips:\n",
    "    selected_df = pd.concat(selected_clips, ignore_index=True)\n",
    "\n",
    "    for _, row in selected_df.iterrows():\n",
    "        class_name = row['class']\n",
    "        class_dir = Path(output_dir) / class_name\n",
    "        class_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        score = row['score']\n",
    "        offset = int(row['offset'])\n",
    "\n",
    "        audio_path = Path(row['file_path'])  # Use full path directly\n",
    "        filename = audio_path.name\n",
    "        output_filename = f\"{score}_{offset}_{filename}\"\n",
    "\n",
    "        try:\n",
    "            audio = Audio.from_file(audio_path, offset=offset, duration=3)\n",
    "            audio.save(class_dir / output_filename)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {audio_path}: {e}\")\n",
    "else:\n",
    "    print(\"No clips selected for validation.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenSoundscape",
   "language": "python",
   "name": "opensoundscape"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
