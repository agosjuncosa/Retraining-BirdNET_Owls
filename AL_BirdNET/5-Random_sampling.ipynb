{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "787a4561-e992-4b43-958c-0b6af7524f7b",
   "metadata": {},
   "source": [
    "## Random Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a969cc-c8e4-419b-aa54-edc4c2f8387c",
   "metadata": {},
   "source": [
    "Select 248 random clips in total (considering 31 classes) or 8 random clips per class. Although I am including 31 classes to respect the 20% of random sampled clips I am avoinding including clips labeled as Res Junglefowl, as there are so many and I want to avoid labeling clips from this class. The same as other confounding sounds. For these I will only include them in uncertainty sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76684568-0b84-4adb-8d91-33e88c64a591",
   "metadata": {},
   "source": [
    "Global Random Sampling:\n",
    "\n",
    "Perform random sampling across all remaining predictions without class constraints.\n",
    "Adjust sampling to exclude clips belonging to any unwanted classes (e.g., Gallus_gallus), if needed in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e26c1c6-b895-4ecc-8319-08ac8867c0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agosjuncosa/anaconda3/envs/opensoundscape/lib/python3.9/site-packages/opensoundscape/ml/cnn.py:18: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import random\n",
    "from opensoundscape import Audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "244091f9-2eac-44ae-a024-39f9f35e4b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These paths never change\n",
    "tracker_file = '/mnt/d/retraining_BirdNET_2025/model_train/train_set/training_set_tracker.csv'\n",
    "audio_files_dir = '/mnt/d/retraining_BirdNET_2025/iterative_training/input_20%/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f6fc3-aeb0-4781-8a9d-c76196f90df9",
   "metadata": {},
   "source": [
    "*Modify the paths below accordingly.*  \n",
    "\n",
    "Remember during **iteration 1** the results will come from **model_0**. On **iteration 2** the results will come from **model_1** and so on..  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ff11ea-b609-41ab-aacb-c543f292120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "annotations_file = '/mnt/d/retraining_BirdNET_2025/iterative_training/results/model_0_s1_t0.01/BirdNET_SelectionTable.txt'\n",
    "output_dir = '/mnt/d/retraining_BirdNET_2025/iterative_training/segments_validation/it_1_s1_t0.01/random/'\n",
    "\n",
    "random_clip_count = 240  # Number of random clips to sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b52e36f3-de9f-4613-a957-9e677f32b644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BirdNET predictions\n",
    "predictions = pd.read_csv(annotations_file, sep='\\t', usecols=['Begin Path', 'File Offset (s)', 'Common Name', 'Confidence'])\n",
    "predictions.rename(columns={\n",
    "    'Begin Path': 'file_path',\n",
    "    'File Offset (s)': 'offset',\n",
    "    'Common Name': 'class',\n",
    "    'Confidence': 'score'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "048428f0-2719-4a97-b147-40b8d96c4cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct `offset_filename` using ONLY offset and filename with extension\n",
    "predictions['offset_filename'] = predictions.apply(\n",
    "    lambda row: f\"{int(row['offset'])}_{Path(row['file_path']).name}\", axis=1  # Keep original extension\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b944f3da-ae69-4792-ab23-688957a4ebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract elements 1 to 5 elements of the filename for comparison\n",
    "def extract_core_filename(filename):\n",
    "    parts = Path(filename).stem.split('_')  # Remove extension and split filename\n",
    "    return '_'.join(parts[1:6])  # Extract elements 1 to 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15950dd8-53e5-4129-be4d-57bcf4588533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training set tracker\n",
    "if Path(tracker_file).exists():\n",
    "    tracker = pd.read_csv(tracker_file)\n",
    "\n",
    "    # Only consider files added in iteration 1 and onwards\n",
    "    tracker = tracker[tracker['iteration'] >= 1]\n",
    "\n",
    "    # Extract core filename\n",
    "    tracker['core_filename'] = tracker['file'].apply(lambda x: extract_core_filename(Path(x).name))\n",
    "    tracker_filenames = tracker['core_filename'].tolist()\n",
    "else:\n",
    "    tracker_filenames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "903d5c3d-0526-43f6-a0df-19b2e3da4f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the same logic to predictions\n",
    "predictions['core_filename'] = predictions['offset_filename'].apply(lambda x: extract_core_filename(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2aa0e49-3723-41e7-ab58-3200d1391187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered predictions: 2516070 clips remaining\n"
     ]
    }
   ],
   "source": [
    "# Filter out unwanted classes\n",
    "unwanted_classes = [\"Red Junglefowl\"]\n",
    "# Apply both filters in one step using `~` (negation) to filter clips already in the traini set and avoid includin unwanted classes\n",
    "predictions = predictions[\n",
    "    (~predictions[\"class\"].isin(unwanted_classes)) & \n",
    "    (~predictions[\"core_filename\"].isin(tracker_filenames))\n",
    "]\n",
    "\n",
    "# Display result for verification\n",
    "print(f\"Filtered predictions: {len(predictions)} clips remaining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a7a1c5e-9e7c-4d7f-95a9-3528eeecb222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sampling complete. Clips saved.\n"
     ]
    }
   ],
   "source": [
    "# Randomly sample clips\n",
    "random_samples = predictions.sample(min(random_clip_count, len(predictions)), random_state=42)\n",
    "\n",
    "# Save selected random clips\n",
    "for _, row in random_samples.iterrows():\n",
    "    class_name = row[\"class\"]\n",
    "    class_dir = Path(output_dir) / class_name\n",
    "    class_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    score = row['score']\n",
    "    offset = int(row['offset'])\n",
    "    filename = Path(row['file_path']).name\n",
    "    output_filename = f\"{score}_{offset}_{filename}\"\n",
    "  \n",
    "            \n",
    "    # Assuming clips are extracted similarly as before\n",
    "    audio_path = Path(audio_files_dir) / filename\n",
    "    try:\n",
    "        # Extract audio segment using Opensoudscape Audio class\n",
    "        audio = Audio.from_file(audio_path, offset=offset, duration=3)\n",
    "        audio.save(class_dir / output_filename)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        \n",
    "print(\"Random sampling complete. Clips saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenSoundscape",
   "language": "python",
   "name": "opensoundscape"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
