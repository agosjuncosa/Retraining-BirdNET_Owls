{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "787a4561-e992-4b43-958c-0b6af7524f7b",
   "metadata": {},
   "source": [
    "## Random Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a969cc-c8e4-419b-aa54-edc4c2f8387c",
   "metadata": {},
   "source": [
    "Select 248 random clips in total (considering 31 classes) or 8 random clips per class. Although I am including 31 classes to respect the 20% of random sampled clips I am avoinding including clips labeled as Res Junglefowl, as there are so many and I want to avoid labeling clips from this class. The same as other confounding sounds. For these I will only include them in uncertainty sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76684568-0b84-4adb-8d91-33e88c64a591",
   "metadata": {},
   "source": [
    "Global Random Sampling:\n",
    "\n",
    "Perform random sampling across all remaining predictions without class constraints.\n",
    "Adjust sampling to exclude clips belonging to any unwanted classes (e.g., Gallus_gallus), if needed in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e26c1c6-b895-4ecc-8319-08ac8867c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import random\n",
    "from opensoundscape import Audio\n",
    "\n",
    "# Paths\n",
    "annotations_file = '/mnt/d/retraining_BirdNET/iterative_training_2025/output_results_2025/model_0/BirdNET_SelectionTable.txt'\n",
    "tracker_file = '/mnt/d/retraining_BirdNET/model_train_2025/training_set_tracker.csv'\n",
    "audio_files_dir = '/mnt/d/retraining_BirdNET/iterative_training_2025/input_20%/'\n",
    "output_dir = '/mnt/d/retraining_BirdNET/iterative_training_2025/segments_validation_2025/model_0/'\n",
    "\n",
    "iteration_number = 1  # Current iteration number\n",
    "random_clip_count = 248  # Number of random clips to sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52e36f3-de9f-4613-a957-9e677f32b644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BirdNET predictions\n",
    "predictions = pd.read_csv(annotations_file, sep='\\t', usecols=['Begin Path', 'File Offset (s)', 'Common Name', 'Confidence'])\n",
    "predictions.rename(columns={\n",
    "    'Begin Path': 'file_path',\n",
    "    'File Offset (s)': 'offset',\n",
    "    'Common Name': 'class',\n",
    "    'Confidence': 'score'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048428f0-2719-4a97-b147-40b8d96c4cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct `offset_filename` using ONLY offset and filename with extension\n",
    "predictions['offset_filename'] = predictions.apply(\n",
    "    lambda row: f\"{int(row['offset'])}_{Path(row['file_path']).name}\", axis=1  # Keep original extension\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15950dd8-53e5-4129-be4d-57bcf4588533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training set tracker\n",
    "if Path(tracker_file).exists():\n",
    "    tracker = pd.read_csv(tracker_file)\n",
    "\n",
    "    # Only consider files added in iteration 1 and onwards\n",
    "    tracker = tracker[tracker['iteration'] >= 1]\n",
    "\n",
    "    # Extract only the first 5 elements of the filename for comparison\n",
    "    def extract_core_filename(filename):\n",
    "        parts = Path(filename).stem.split('_')  # Remove extension and split filename\n",
    "        return '_'.join(parts[:5])  # Keep only first 5 elements\n",
    "\n",
    "    tracker['core_filename'] = tracker['file'].apply(lambda x: extract_core_filename(Path(x).name))\n",
    "    tracker_filenames = tracker['core_filename'].tolist()\n",
    "else:\n",
    "    tracker_filenames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903d5c3d-0526-43f6-a0df-19b2e3da4f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the same logic to predictions\n",
    "predictions['core_filename'] = predictions['offset_filename'].apply(lambda x: extract_core_filename(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aa0e49-3723-41e7-ab58-3200d1391187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out unwanted classes\n",
    "unwanted_classes = [\"Gallus gallus_Red Junglefowl\"]\n",
    "# Apply both filters in one step using `~` (negation) to filter clips already in the traini set and avoid includin unwanted classes\n",
    "predictions = predictions[\n",
    "    (~predictions[\"class\"].isin(unwanted_classes)) & \n",
    "    (~predictions[\"core_filename\"].isin(tracker_filenames))\n",
    "]\n",
    "\n",
    "# Display result for verification\n",
    "print(f\"Filtered predictions: {len(predictions)} clips remaining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7a1c5e-9e7c-4d7f-95a9-3528eeecb222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample clips\n",
    "random_samples = predictions.sample(min(random_clip_count, len(predictions)), random_state=42)\n",
    "\n",
    "# Save selected random clips\n",
    "for _, row in random_samples.iterrows():\n",
    "    class_name = row[\"class\"]\n",
    "    class_dir = Path(output_dir) / class_name\n",
    "    class_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    score = row['score']\n",
    "    offset = int(row['offset'])\n",
    "    filename = Path(row['file_path']).name\n",
    "    output_filename = f\"{score}_{offset}_{filename}\"\n",
    "  \n",
    "            \n",
    "    # Assuming clips are extracted similarly as before\n",
    "    audio_path = Path(audio_files_dir) / filename\n",
    "    try:\n",
    "        # Extract audio segment using Opensoudscape Audio class\n",
    "        audio = Audio.from_file(audio_path, offset=offset, duration=3)\n",
    "        audio.save(class_dir / output_filename)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        \n",
    "print(\"Random sampling complete. Clips saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenSoundscape",
   "language": "python",
   "name": "opensoundscape"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
