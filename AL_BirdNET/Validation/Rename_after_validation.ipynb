{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f3ea39-a756-4300-88a0-989e96618fb2",
   "metadata": {},
   "source": [
    "### Recursively Rename Files After Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1198f60-f5ad-41c6-8471-ac2e47f837b3",
   "metadata": {},
   "source": [
    "### **Test before use on real data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d726d85-6ae5-4dfe-909e-f5b9c45ab994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import glob  # To find the `_Validation.txt` files dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7618783-a8fc-4ccc-8ee6-5cad9beb35b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "prev_val_clips = \"/mnt/d/retraining_BirdNET_2025/iterative_training/segments_validation/uncertainty/it_1_s0.5_t0.1/\"\n",
    "new_clips_dir = \"/mnt/d/retraining_BirdNET_2025/iterative_training/segments_validation/uncertainty/it_1_s1_t0.01/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f299ea-6d06-4858-85f7-bb70fde5b1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract core filename (ignoring score)\n",
    "def extract_core_filename(filename):\n",
    "    parts = Path(filename).stem.split('_')  # Remove extension and split filename\n",
    "    return '_'.join(parts[1:6])  # Extract offset, siteID, survey night, date, time\n",
    "\n",
    "# Iterate through each class folder in the previous validation clips\n",
    "for class_folder in os.listdir(prev_val_clips):\n",
    "    old_class_path = os.path.join(prev_val_clips, class_folder)\n",
    "    new_class_path = os.path.join(new_clips_dir, class_folder)\n",
    "\n",
    "    # Ensure the class exists in both directories\n",
    "    if not os.path.isdir(old_class_path) or not os.path.isdir(new_class_path):\n",
    "        continue\n",
    "\n",
    "    # Find the validation .txt file (assuming one per class)\n",
    "    old_txt_files = glob.glob(os.path.join(old_class_path, \"*_Validation.txt\"))\n",
    "    new_txt_files = glob.glob(os.path.join(new_class_path, \"*_Validation.txt\"))\n",
    "\n",
    "    if len(old_txt_files) == 0:\n",
    "        print(f\"⚠ No previous validation file found in {class_folder}, skipping...\")\n",
    "        continue\n",
    "    if len(new_txt_files) == 0:\n",
    "        print(f\"⚠ No new validation file found in {class_folder}, skipping...\")\n",
    "        continue\n",
    "\n",
    "    old_txt_file = old_txt_files[0]  # Pick the old validation file\n",
    "    new_txt_file = new_txt_files[0]  # Pick the new validation file\n",
    "\n",
    "    # Load old validation data\n",
    "    df_old = pd.read_csv(old_txt_file, delimiter='\\t', usecols=[\"Begin File\", \"Eval\", \"Annotation\"])\n",
    "\n",
    "    # Create a dictionary mapping core filenames to their Eval & Annotation\n",
    "    validated_clips = {\n",
    "        extract_core_filename(row[\"Begin File\"]): (row[\"Eval\"], row[\"Annotation\"])\n",
    "        for _, row in df_old.iterrows()\n",
    "    }\n",
    "\n",
    "    # Load new validation data\n",
    "    df_new = pd.read_csv(new_txt_file, delimiter='\\t')\n",
    "\n",
    "    # Ensure required columns exist\n",
    "    if \"Begin File\" not in df_new.columns:\n",
    "        print(f\"⚠ Skipping {class_folder} due to missing 'Begin File' column in new validation file.\")\n",
    "        continue\n",
    "\n",
    "    # Add Eval and Annotation columns if not present\n",
    "    if \"Eval\" not in df_new.columns:\n",
    "        df_new[\"Eval\"] = \"\"\n",
    "    if \"Annotation\" not in df_new.columns:\n",
    "        df_new[\"Annotation\"] = \"\"\n",
    "\n",
    "    # Update new validation file with matched Eval & Annotation values\n",
    "    for index, row in df_new.iterrows():\n",
    "        core_name = extract_core_filename(row[\"Begin File\"])\n",
    "        if core_name in validated_clips:\n",
    "            df_new.at[index, \"Eval\"] = validated_clips[core_name][0]  # Copy Eval\n",
    "            df_new.at[index, \"Annotation\"] = validated_clips[core_name][1]  # Copy Annotation\n",
    "\n",
    "    # Save the updated validation file\n",
    "    df_new.to_csv(new_txt_file, sep='\\t', index=False)\n",
    "\n",
    "    print(f\"✔ Updated {new_txt_file} with preserved validation data.\")\n",
    "\n",
    "print(\"✅ All annotation files updated successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
