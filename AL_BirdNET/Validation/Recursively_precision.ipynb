{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "992d5ecd-fa41-43ac-8e57-498981ca64df",
   "metadata": {},
   "source": [
    "### Edit to recursively compute precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d2df9-667d-4d8a-99d9-e1e609da7916",
   "metadata": {},
   "source": [
    "Recursively compute precision for each class using the Eval column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173ce77d-7729-4aa6-a5cb-a0176c0c9e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56427f69-a235-4a0f-b4ed-2af6ad84171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize directory - CHANGE IT ACCORDINGLY\n",
    "recs_directory = \"/mnt/d/retraining_BirdNET_2025/iterative_training/segments_validation/it_1_s1_t0.01/uncertainty/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d3920c-5d95-44e8-9833-c31a1b9d25d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store results\n",
    "precision_data = []\n",
    "\n",
    "for class_folder in os.listdir(recs_directory):\n",
    "    class_path = os.path.join(recs_directory, class_folder)\n",
    "    \n",
    "\n",
    "    # Try to find the validation file:\n",
    "    # 1) Look in the top_scoring subfolder\n",
    "    top_scoring_path = os.path.join(class_path, \"top_scoring\")\n",
    "    if os.path.isdir(top_scoring_path):\n",
    "        txt_files = glob.glob(os.path.join(top_scoring_path, \"*_Validation.txt\"))\n",
    "    else:\n",
    "        # 2) If no top_scoring folder exists, look in directly in the class folder\n",
    "        txt_files = glob.glob(os.path.join(class_path, \"*_Validation.txt\"))\n",
    "        \n",
    "    if not txt_files:\n",
    "        continue # Skip if there is no Validation file\n",
    "    \n",
    "    txt_file = txt_files[0]  # Pick the first found file\n",
    "    class_name = class_folder  # Use folder name as class name\n",
    "\n",
    "    try:\n",
    "        # Load the .txt file\n",
    "        df = pd.read_csv(txt_file, delimiter='\\t')\n",
    "\n",
    "        # Compute precision: (count of 1s) / (total count)\n",
    "        total_samples = len(df) # Not sure if use this or use only the ones I am scoring with 1 or 0 \n",
    "        positive_samples = df[\"Eval\"].astype(str).str.count(\"1\").sum()\n",
    "        precision = positive_samples / total_samples if total_samples > 0 else 0\n",
    "\n",
    "        # Store the result\n",
    "        precision_data.append({\"class\": class_name, \"precision\": round(precision, 4)})\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {txt_file}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Convert list to DataFrame\n",
    "precision_df = pd.DataFrame(precision_data)\n",
    "# Save to CSV\n",
    "precision_df.to_csv(os.path.join(recs_directory, \"precision.csv\"), index=False)\n",
    "\n",
    "print(f\"Precision for all classes computed and saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f100e092-b0b5-4a2f-91dd-930c6b519f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
