{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "289ae21f-7087-40cb-b204-812ce65a3634",
   "metadata": {},
   "source": [
    "## Create continuous score labels' data frame for BirdNET detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74124aa4-f18d-4233-bfc1-548235ae04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b17f550-4117-4d85-9d6b-5299f7c40bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the duration of the wav file\n",
    "def get_wav_duration(wav_path):\n",
    "    return librosa.get_duration(path=wav_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b045924d-3b34-4030-b3fd-c9a5151159d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directories containing the .wav files and BirdNET output .txt files\n",
    "wav_directory = '/mnt/e/retraining_BirdNET/model_test/input_ready/'\n",
    "txt_directory = '/mnt/e/retraining_BirdNET/model_test/results/2nd_model_alternative_autotune/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2eeea4c-89cd-4e45-937a-3f292afb39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all .wav files\n",
    "wav_files = [f for f in os.listdir(wav_directory) if f.lower().endswith('.wav')]\n",
    "# this code transform all extensions into lowecase before comparing them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbc57294-b979-421d-a704-bd4849026343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired order of columns\n",
    "desired_order = [\n",
    "    \"Barn Owl\", \"Rusty-barred Owl_song\", \"Rusty-barred Owl_call\", \"Rusty-barred Owl_call1\",\n",
    "    \"Ferruginous Pygmy-Owl\", \"Tropical Screech-Owl\", \"Black-capped Screech-Owl\", \"Long-tufted Screech-Owl\",\n",
    "    \"Buff-fronted Owl\", \"Rufous Nightjar\", \"Silky-tailed Nightjar\", \"Stygian Owl_song\", \"Stygian Owl_call\",\n",
    "    \"Striped Owl_song\", \"Striped Owl_call\", \"Burrowing Owl\", \"Rufous-capped Motmot\", \"Black-banded Owl\",\n",
    "    \"Mottled Owl_song\", \"Mottled Owl_call\", \"Brown Tinamou\", \"Ocellated Poorwill\", \"Long-tailed Potoo\",\n",
    "    \"Common Potoo\", \"Common Pauraque\", \"Short-tailed Nighthawk\", \"Spot-winged Wood-Quail\", \"Tawny-browed Owl\",\n",
    "    \"Little Nightjar\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8adaa7f0-a73d-4a99-a3c5-46d259743d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store dataframes for each file\n",
    "all_dfs = []\n",
    "\n",
    "# Loop through each .wav file\n",
    "for wav_file in wav_files:\n",
    "    # Get the duration of the .wav file\n",
    "    duration = get_wav_duration(os.path.join(wav_directory, wav_file))\n",
    "    \n",
    "    # Create a template dataframe with 3-second segments\n",
    "    segments = np.arange(0, duration, 3)\n",
    "    end_segments = np.clip(segments + 3, None, duration)\n",
    "    template_df = pd.DataFrame({\n",
    "        'file': os.path.join(wav_directory, wav_file),\n",
    "        'start_time': segments,\n",
    "        'end_time': end_segments\n",
    "    })\n",
    "    \n",
    "    # Initialize class columns with zeros\n",
    "    for cls in desired_order:\n",
    "        template_df[cls] = 0.0\n",
    "    \n",
    "    # Append the dataframe for this file to the list\n",
    "    all_dfs.append(template_df)\n",
    "    \n",
    "# Concatenate all dataframes into a single dataframe\n",
    "labels_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Fill NAs with 0 to ensure all segments without detections are filled with zeros\n",
    "labels_df = labels_df.fillna(0)\n",
    "\n",
    "# Reorder the columns to match the desired order\n",
    "labels_df = labels_df[['file', 'start_time', 'end_time'] + desired_order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1330c20-443c-492b-b5d1-c73071c2b55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in final dataframe: 4342\n"
     ]
    }
   ],
   "source": [
    "# Now read the BirdNET .txt files and update the labels dataframe\n",
    "# Loop through each .wav file again to process corresponding .txt files\n",
    "for wav_file in wav_files:\n",
    "    # Construct the corresponding BirdNET .txt file name\n",
    "    txt_file = wav_file.replace('.wav', '.BirdNET.selection.table.txt').replace('.WAV', '.BirdNET.selection.table.txt')\n",
    "    txt_path = os.path.join(txt_directory, txt_file)\n",
    "    \n",
    "    # Read the BirdNET output annotation file into a dataframe\n",
    "    if os.path.exists(txt_path):\n",
    "        annotations = pd.read_csv(txt_path, delimiter='\\t')\n",
    "        # Extract relevant columns: start_time, end_time, annotation, score\n",
    "        annotations = annotations[['Begin Time (s)', 'End Time (s)', 'Common Name', 'Confidence']]\n",
    "        annotations.columns = ['start_time', 'end_time', 'annotation', 'score']\n",
    "        \n",
    "        # Update the labels dataframe with the scores\n",
    "        for _, row in annotations.iterrows():\n",
    "            # Find the 3-second segment that overlaps with the annotation\n",
    "            overlapping_segments = labels_df[\n",
    "                (labels_df['file'] == os.path.join(wav_directory, wav_file)) &\n",
    "                (labels_df['start_time'] < row['end_time']) & \n",
    "                (labels_df['end_time'] > row['start_time'])\n",
    "            ]\n",
    "            \n",
    "            for idx in overlapping_segments.index:\n",
    "                labels_df.loc[idx, row['annotation']] = row['score']\n",
    "\n",
    "# Remove the 'nocall' column if it exists\n",
    "if 'nocall' in labels_df.columns:\n",
    "    labels_df = labels_df.drop(columns=['nocall'])\n",
    "#Quizas deba modificar esto para que directamente elimine todas las columnas que no esten en desired order.\n",
    "\n",
    "# Save the updated labels dataframe to a CSV file\n",
    "labels_df.to_csv('/mnt/e/retraining_BirdNET/model_test/results/2nd_model_alternative_autotune/predicted_labels.csv', index=False)\n",
    "\n",
    "# Verify the number of rows in the final dataframe\n",
    "print(f\"Number of rows in final dataframe: {len(labels_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a4bf23-84fb-4276-8f18-d37492cef0f9",
   "metadata": {},
   "source": [
    "Modify end_time column to match 3 s segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "334be896-fd7b-463d-a693-3c7afc8eab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file directly into a DataFrame\n",
    "data_path = '/mnt/e/retraining_BirdNET/model_test/results/2nd_model_alternative_autotune/predicted_labels.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Function to adjust times\n",
    "def adjust_times(group):\n",
    "    # For groups with only one segment and the end time is less than 3\n",
    "    if len(group) == 1 and group.iloc[0]['end_time'] < 3:\n",
    "        group.iloc[0, group.columns.get_loc('end_time')] = 3\n",
    "    else:\n",
    "        # Process as usual for last row adjustments\n",
    "        last_row = group.iloc[-1]\n",
    "        if last_row['end_time'] % 3 != 0:\n",
    "            if len(group) > 1:  # There's a previous row to reference\n",
    "                new_start_time = group.iloc[-2]['end_time']\n",
    "            else:  # Single row handling\n",
    "                new_start_time = 0\n",
    "            new_end_time = 3 * ((new_start_time // 3) + 1)\n",
    "            group.iloc[-1, group.columns.get_loc('start_time')] = new_start_time\n",
    "            group.iloc[-1, group.columns.get_loc('end_time')] = new_end_time\n",
    "    return group\n",
    "\n",
    "# Apply the function to each group of audio files\n",
    "adjusted_df = df.groupby('file').apply(adjust_times)\n",
    "\n",
    "# Save the adjusted DataFrame to a new CSV file\n",
    "adjusted_df.to_csv('/mnt/e/retraining_BirdNET/model_test/results/2nd_model_alternative_autotune/predicted_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f11d9f6-e4e5-482b-a140-1df7869dad42",
   "metadata": {},
   "source": [
    "Check that true labels df and predicted labels are aligned and have the same lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3d5b29d-2ba2-4040-b869-1dca73367699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in true labels not in predicted labels: set()\n",
      "Files in predicted labels not in true labels: set()\n",
      "Number of unique files in true labels: 205\n",
      "Number of unique files in predicted labels: 205\n",
      "Dataframes are aligned and ready for mAP calculation.\n"
     ]
    }
   ],
   "source": [
    "# Load the true labels dataframe\n",
    "true_labels_df = pd.read_csv('/mnt/e/retraining_BirdNET/model_test/input_ready/one-hot-encoded_validation.csv')\n",
    "\n",
    "# Ensure the dataframes are aligned\n",
    "true_labels_df = true_labels_df.sort_values(by=['file', 'start_time']).reset_index(drop=True)\n",
    "labels_df = labels_df.sort_values(by=['file', 'start_time']).reset_index(drop=True)\n",
    "\n",
    "# Check if the unique file names match between the true labels and predicted labels dataframes\n",
    "unique_true_files = set(true_labels_df['file'].unique())\n",
    "unique_pred_files = set(labels_df['file'].unique())\n",
    "\n",
    "missing_in_pred = unique_true_files - unique_pred_files\n",
    "missing_in_true = unique_pred_files - unique_true_files\n",
    "\n",
    "print(f\"Files in true labels not in predicted labels: {missing_in_pred}\")\n",
    "print(f\"Files in predicted labels not in true labels: {missing_in_true}\")\n",
    "print(f\"Number of unique files in true labels: {len(unique_true_files)}\")\n",
    "print(f\"Number of unique files in predicted labels: {len(unique_pred_files)}\")\n",
    "\n",
    "# Align the dataframes if necessary\n",
    "if missing_in_pred or missing_in_true:\n",
    "    print(\"Dataframes are not aligned properly. Please check the missing files and ensure they are processed correctly.\")\n",
    "else:\n",
    "    print(\"Dataframes are aligned and ready for mAP calculation.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
